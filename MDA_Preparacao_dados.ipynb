{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YiG1TTPeNoWi"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pima-indians-diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_csv\n\u001b[1;32m---> 14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpima-indians-diabetes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApresentando o shape dos dados (dimenssoes)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\josel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\josel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\josel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pima-indians-diabetes.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para tratamentos de valores ausentes\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "\n",
    "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"Conhecendo os dados estatisticos dos dados carregados (describe)\")\n",
    "print(dataset.describe())\n",
    "\n",
    "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
    "\t\t\"os 10 primeiros registros (head(10))\")\n",
    "print(dataset.head(10))\n",
    "\n",
    "print(\"Quantidade de pontos que possue 0 como valor\")\n",
    "print((dataset[[1,2,3,4,5]] == 0).sum())\n",
    "\n",
    "# Marcar os valores ausentes como NaN = not a number\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, numpy.NaN)\n",
    "\n",
    "print(\"Realiza a contagem de valores NaN em cada coluna\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
    "\t\t\"os 10 primeiros registros (head(10))\")\n",
    "print(dataset.head(10))\n",
    "\n",
    "#Abordagems para substituicao do NaN\n",
    "#usando a media (mean) mediana (median) coluna por coluna\n",
    "dataset.fillna(dataset.median(), inplace=True)\n",
    "\n",
    "#preenchendo com as ocorrencias mais próximas\n",
    "#dataset.fillna(method='ffill',inplace=True)\n",
    "\n",
    "# Removendo registros que possuem valores ausentes (NaN)\n",
    "#dataset.dropna(inplace=True)\n",
    "\n",
    "# Preenchendo os valores ausentes com base na media dos valores da coluna\n",
    "# existe ainda as opcoes via mediana e valores mais frequentes\n",
    "#dataset.fillna(dataset.mean(), inplace=True)\n",
    "\n",
    "#fazendo interpolacao para encontrar os novos valores para NaN\n",
    "#dataset=dataset.interpolate()\n",
    "\n",
    "print(\"Mostra a quantidade de valores ausentes (NaN) de cada coluna\")\n",
    "print(dataset.isnull().sum())\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
    "\t\t\"os 20 primeiros registros (head(20))\")\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkFAkyGTbPro"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Realizando a remocao de valores aberrantes de atributos\n",
    "\n",
    "\n",
    "#Utilizando a base de dados com caracteristicas de carros\n",
    "dataset = pd.read_csv('/content/mtcars.csv')\n",
    "\n",
    "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"Conhecendo os dados estatisticos dos dados carregados (describe)\")\n",
    "print(dataset.describe())\n",
    "\n",
    "print('Apresentando os primeiros registros')\n",
    "print(dataset.head())\n",
    "\n",
    "# print('Quantidade de valores zeros')\n",
    "# print((dataset[['cyl','hp']] == 0).sum())\n",
    "\n",
    "#Gerando boxplot para a caracteristia HP\n",
    "sns.boxplot(data=dataset,x=dataset['hp'])\n",
    "\n",
    "#obtendo o valor do Q1\n",
    "Q1=dataset['hp'].quantile(0.25)\n",
    "\n",
    "#obtendo o valor do Q3\n",
    "Q3=dataset['hp'].quantile(0.75)\n",
    "\n",
    "#obtendo a faixa de valores interquartil\n",
    "IQR=Q3-Q1\n",
    "\n",
    "print(Q1)\n",
    "\n",
    "print(Q3)\n",
    "\n",
    "print(IQR)\n",
    "\n",
    "Lower_Whisker = Q1-1.5*IQR\n",
    "\n",
    "Upper_Whisker = Q3+1.5*IQR\n",
    "\n",
    "print(Lower_Whisker, Upper_Whisker)\n",
    "\n",
    "dataset = dataset[dataset['hp']< Upper_Whisker]\n",
    "\n",
    "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81e2ceXOijJ0",
    "outputId": "5b32f076-384d-45a1-ec4a-4fcd84d7316a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Score\n",
      "0   George     63\n",
      "1   Andrea     48\n",
      "2  micheal     56\n",
      "3   maggie     75\n",
      "4     Ravi     32\n",
      "5     Xien     77\n",
      "6    Jalpa     85\n",
      "7  Tyieren     22\n",
      "      Name  Score     binned\n",
      "0   George     63   (50, 75]\n",
      "1   Andrea     48   (25, 50]\n",
      "2  micheal     56   (50, 75]\n",
      "3   maggie     75   (50, 75]\n",
      "4     Ravi     32   (25, 50]\n",
      "5     Xien     77  (75, 100]\n",
      "6    Jalpa     85  (75, 100]\n",
      "7  Tyieren     22    (0, 25]\n",
      "      Name  Score binned\n",
      "0   George     63      3\n",
      "1   Andrea     48      2\n",
      "2  micheal     56      3\n",
      "3   maggie     75      3\n",
      "4     Ravi     32      2\n",
      "5     Xien     77      4\n",
      "6    Jalpa     85      4\n",
      "7  Tyieren     22      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Realizando a discretizacao de atributos continuos\n",
    "#Create a DataFrame\n",
    "df1 = {\n",
    "    'Name':['George','Andrea','micheal','maggie','Ravi','Xien','Jalpa','Tyieren'],\n",
    "    'Score':[63,48,56,75,32,77,85,22]\n",
    "\n",
    "   }\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(df1,columns=['Name','Score'])\n",
    "print(df1)\n",
    "\n",
    "''' binning or bucketing with range'''\n",
    "\n",
    "bins = [0, 25, 50, 75, 100]\n",
    "df1['binned'] = pd.cut(df1['Score'], bins)\n",
    "print (df1)\n",
    "\n",
    "\n",
    "''' binning or bucketing with labels'''\n",
    "\n",
    "bins = [0, 25, 50, 75, 100]\n",
    "labels =[1,2,3,4]\n",
    "df1['binned'] = pd.cut(df1['Score'], bins,labels=labels)\n",
    "print (df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2szFGQPMlA1g"
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#Script que padroniza os dados para media 0 e desvio 1\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning\n",
    "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "#padroniza os dados com media 0 e desvio 1\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificados\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un_Lwa9MlTYV"
   },
   "outputs": [],
   "source": [
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para normalizacao dos dados\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning\n",
    "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "#normaliza os dados\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificados\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6KSAn0Plf67"
   },
   "outputs": [],
   "source": [
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para a binarizacao de dados\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning\n",
    "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificados\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKjvkbW0liih"
   },
   "outputs": [],
   "source": [
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para re-escala de dados\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv\n",
    "\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning\n",
    "dataframe = read_csv('pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "#realiza a re-escala dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataframe[['preg', 'plas']] = scaler.fit_transform(dataframe[['preg', 'plas']])\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificadoss\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohG9SMyiuom-"
   },
   "outputs": [],
   "source": [
    "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para converter dados categoricos em binarios\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# Define the headers since the data does not have any\n",
    "nomes = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
    "           \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
    "           \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
    "           \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
    "           \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "# Read in the CSV file and convert \"?\" to NaN\n",
    "df = pandas.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data',\n",
    "                  header=None, names=nomes, na_values=\"?\" )\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(df.head())\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"selecionar apenas as colunas que sao do tipo objeto/categorigos\")\n",
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "print(obj_df.head())\n",
    "\n",
    "print(\"verificar a existencia de dados ausentes\")\n",
    "print(obj_df[obj_df.isnull().any(axis=1)])\n",
    "\n",
    "print(\"realiza a contagem de dados de um atributo\")\n",
    "print(obj_df[\"num_doors\"].value_counts())\n",
    "\n",
    "print(\"realiza o preenchimento NaN com um valor especifico\")\n",
    "obj_df = obj_df.fillna({\"num_doors\": \"four\"})\n",
    "\n",
    "#conversao de categorigo para binario\n",
    "print(pandas.get_dummies(obj_df, columns=[\"drive_wheels\"]).head())\n",
    "\n",
    "dfb = pandas.get_dummies(obj_df, columns=[\"drive_wheels\"]);\n",
    "\n",
    "print(pandas.get_dummies(dfb, columns=[\"body_style\"]).head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UdQBGJDTt95"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "\n",
    "# Load iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Constroi um classificador com arvore de decisao\n",
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dt.fit(X, y)\n",
    "dotfile = open(\"dt-iris.dot\", 'w')\n",
    "tree.export_graphviz(dt, out_file=dotfile, feature_names=iris.feature_names)\n",
    "dotfile.close()\n",
    "print(\"Arvore de decisao gerada no diretorio!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
